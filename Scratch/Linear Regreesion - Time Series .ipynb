{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling as pp\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import r2_score, median_absolute_error, mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error, mean_squared_error, mean_squared_log_error\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose the data\n",
    "Art_Code = 1011001030040\n",
    "Zone = 'Zone 03'\n",
    "Mill = 'PDKrw'\n",
    "Algo = 'LR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the data if the data doesn't meet with our requirement (check the slide/power point) then change above combinations.\n",
    "\n",
    "\n",
    "#Import Data\n",
    "df = pd.read_csv('rs_mergedata_03_2.csv')\n",
    "del df['Unnamed: 0']\n",
    "df2 = df[df['Art_Code'] == Art_Code]\n",
    "print(df2['Zone'].value_counts())\n",
    "df2 = df2[df2['Zone'] == Zone]\n",
    "print(df2['Mill'].value_counts())\n",
    "df2 = df2[df2['Mill'] == Mill]\n",
    "df2 = df2[['GI_Date','Art_Code','Value (IDR)','Mill','Holiday','Zone','Disc_Amount','NW(Kg)']]\n",
    "df2.columns = ['GI_Date','Art_Code','Value (IDR)','Mill','Holiday','Zone','Disc_Amount','NW(Ton)']\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('Date Min: ',df2['GI_Date'].min())\n",
    "print('Date Max',df2['GI_Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Data\n",
    "df = pd.read_csv('rs_mergedata_03_2.csv')\n",
    "del df['Unnamed: 0']\n",
    "df2 = df[df['Art_Code'] == Art_Code]\n",
    "df2 = df2[df2['Zone'] == Zone]\n",
    "df2 = df2[df2['Mill'] == Mill]\n",
    "df2 = df2[['GI_Date','Art_Code','Value (IDR)','Mill','Holiday','Zone','Disc_Amount','NW(Kg)']]\n",
    "df2.columns = ['GI_Date','Art_Code','Value (IDR)','Mill','Holiday','Zone','Disc_Amount','NW(Ton)']\n",
    "#df2['Value (IDR)'] = df2['Value (IDR)']/1000\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('Date Min: ',df2['GI_Date'].min())\n",
    "print('Date Max',df2['GI_Date'].max())\n",
    "\n",
    "# df2['NW(Ton)'] = df2['NW(Ton)'].replace(0,np.NAN)\n",
    "# df2['NW(Ton)'] = df2['NW(Ton)'].astype(float).interpolate(method='linear', limit_direction='forward', axis=0)\n",
    "a2 = df2.copy()\n",
    "a = a2['NW(Ton)'].tolist()\n",
    "b = a2['Value (IDR)'].tolist()\n",
    "\n",
    "\n",
    "#########################################################################################################\n",
    "\n",
    "\n",
    "#4 days Before\n",
    "NW4 = []\n",
    "i = 0\n",
    "while i < len(a)-4:\n",
    "    if i < 4:\n",
    "        NW4.insert(i,a[i])\n",
    "    NW4.append(a[i]+a[i+1]+a[i+2]+a[i+3])\n",
    "    i += 1\n",
    "a2['4 days'] = NW4\n",
    "\n",
    "\n",
    "\n",
    "#8 days Before\n",
    "NW8 = []\n",
    "i = 0\n",
    "while i < len(a)-8:\n",
    "    if i < 8:\n",
    "        NW8.insert(i,a[i])\n",
    "    NW8.append(a[i]+a[i+1]+a[i+2]+a[i+3]+a[i+4]+a[i+5]+a[i+6]+a[i+7])\n",
    "    i += 1\n",
    "a2['8 days'] = NW8\n",
    "\n",
    "\n",
    "#12 days before\n",
    "NW12 = []\n",
    "i = 0\n",
    "while i < len(a)-12:\n",
    "    if i < 12:\n",
    "        NW12.insert(i,a[i])\n",
    "    NW12.append(a[i]+a[i+1]+a[i+2]+a[i+3]+a[i+4]+a[i+5]+a[i+6]+a[i+7]+a[i+8]+a[i+9]+a[i+10]+a[i+11])\n",
    "    i += 1\n",
    "a2['12 days'] = NW12\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "print('Art_Code: ',a2['Art_Code'].unique())\n",
    "print('Zone: ',a2['Zone'].unique())\n",
    "print('Mill: ',a2['Mill'].unique())\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "a2['GI_Date'] = pd.to_datetime(a2['GI_Date'])\n",
    "a2 = a2.groupby('GI_Date')['NW(Ton)','4 days','8 days','12 days','Holiday'].sum().reset_index()\n",
    "a2 = a2.set_index('GI_Date')\n",
    "\n",
    "data2 = a2[['NW(Ton)','4 days','8 days','12 days','Holiday']].resample('W').sum().reset_index()\n",
    "data = data2.copy()\n",
    "del data['GI_Date']\n",
    "print(data.shape)\n",
    "data.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift data means that the data will be cutted off until the last of row number. The rest of the data will become a test data.\n",
    "#Make sure the test data starts from March 2019.\n",
    "\n",
    "test = data2.shift(-165)\n",
    "test2 = test[['4 days','8 days','12 days','Holiday']]\n",
    "test2 = test2.dropna()\n",
    "print(test2.shape)\n",
    "test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###############################################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import TimeSeriesSplit # you have everything done for you\n",
    "\n",
    "\n",
    "# for time-series cross-validation set 5 folds \n",
    "tscv = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeseries_train_validation_split(X, y, validation_size):\n",
    "    \"\"\"\n",
    "        Perform train-validation split with respect to time series structure\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the index after which validation set starts\n",
    "    validation_index = int(len(X)*(1-validation_size))\n",
    "    \n",
    "    X_train = X.iloc[:validation_index]\n",
    "    y_train = y.iloc[:validation_index]\n",
    "    X_validation = X.iloc[validation_index:]\n",
    "    y_validation = y.iloc[validation_index:]\n",
    "    \n",
    "    return X_train, X_validation, y_train, y_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['NW(Ton)'].dropna()\n",
    "X = data.dropna().drop(['NW(Ton)'], axis=1)\n",
    "\n",
    "# reserve 20% of data for validation\n",
    "X_train, X_validation, y_train, y_validation = timeseries_train_validation_split(X, y, validation_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning in two lines\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lr.score(X_train,y_train))\n",
    "lr.score(X_validation,y_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot for the validation data\n",
    "def plotModelResults(model, X_train=X_train, X_validation=X_validation, plot_intervals=False, plot_anomalies=False):\n",
    "    \"\"\"\n",
    "        Plots modelled vs fact values, prediction intervals and anomalies\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    prediction = model.predict(X_validation)\n",
    "    \n",
    "    plt.figure(figsize=(15, 7))\n",
    "    plt.plot(prediction, \"g\", label=\"prediction\", linewidth=2.0)\n",
    "    plt.plot(y_validation.values, label=\"actual\", linewidth=2.0)\n",
    "    \n",
    "    if plot_intervals:\n",
    "        cv = cross_val_score(model, X_train, y_train, \n",
    "                                    cv=tscv, \n",
    "                                    scoring=\"neg_mean_absolute_error\")\n",
    "        mae = cv.mean() * (-1)\n",
    "        deviation = cv.std()\n",
    "        \n",
    "        scale = 1.96\n",
    "        lower = prediction - (mae + scale * deviation)\n",
    "        upper = prediction + (mae + scale * deviation)\n",
    "        \n",
    "        plt.plot(lower, \"r--\", label=\"upper bond / lower bond\", alpha=0.5)\n",
    "        plt.plot(upper, \"r--\", alpha=0.5)\n",
    "        \n",
    "        if plot_anomalies:\n",
    "            anomalies = np.array([np.NaN]*len(y_validation))\n",
    "            anomalies[y_validation<lower] = y_validation[y_validation<lower]\n",
    "            anomalies[y_validation>upper] = y_validation[y_validation>upper]\n",
    "            plt.plot(anomalies, \"o\", markersize=10, label = \"Anomalies\")\n",
    "    \n",
    "    error = mean_absolute_percentage_error(prediction, y_validation)\n",
    "    plt.title(\"Mean absolute percentage error {0:.2f}%\".format(error))\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotModelResults(lr, plot_intervals=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##############################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasil = lr.predict(np.array(test2))\n",
    "hasil = pd.DataFrame(hasil, columns=['Pred'])\n",
    "hasil = pd.concat([test,hasil],1)\n",
    "hasil = hasil.dropna()\n",
    "final = hasil[['GI_Date','NW(Ton)','Pred']]\n",
    "final['Diff'] = final['NW(Ton)'] - final['Pred']\n",
    "final.columns = ['GI_Date','true','pred','diff']\n",
    "print(abs(1 - (abs(sum(final['diff']))/sum(final['pred'])))*100)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month1 =  final[(final['GI_Date'] >= '2019-03-01') & (final['GI_Date'] <= '2019-03-31') ]\n",
    "print(\"Accuracy on March: \",abs(1 - (abs(sum(month1['diff']))/sum(month1['pred'])))*100)\n",
    "print(\"Sum of True Values: \",sum(month1['true']))\n",
    "print(\"Sum of Pred Values: \",sum(month1['pred']))\n",
    "print(\"Sum of Diff Values: \",sum(month1['diff']))\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "month2 =  final[(final['GI_Date'] >= '2019-04-01') & (final['GI_Date'] <= '2019-04-30') ]\n",
    "print(\"Accuracy on April: \",abs(1 - (abs(sum(month2['diff']))/sum(month2['pred'])))*100)\n",
    "print(\"Sum of True Values: \",sum(month2['true']))\n",
    "print(\"Sum of Pred Values: \",sum(month2['pred']))\n",
    "print(\"Sum of Diff Values: \",sum(month2['diff']))\n",
    "\n",
    "\n",
    "print()\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "month3 =  final[(final['GI_Date'] >= '2019-05-01') & (final['GI_Date'] <= '2019-05-31') ]\n",
    "print(\"Accuracy on May: \",abs(1 - (abs(sum(month3['diff']))/sum(month3['pred'])))*100)\n",
    "print(\"Sum of True Values: \",sum(month3['true']))\n",
    "print(\"Sum of Pred Values: \",sum(month3['pred']))\n",
    "print(\"Sum of Diff Values: \",sum(month3['diff']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For this box just running once. After that, please comment because it's just for temporary variable.\n",
    "fnl_rslt_W = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc1 = abs(1 - (abs(sum(month1['diff']))/sum(month1['pred'])))*100\n",
    "sum_true1 = sum(month1['true'])\n",
    "sum_pred1 = sum(month1['pred'])\n",
    "sum_diff1 = sum(month1['diff'])\n",
    "fnl_rslt_W.append([Algo,'March',Art_Code,Zone, Mill, sum_true1,sum_pred1,sum_diff1, acc1])\n",
    "\n",
    "acc2 = abs(1 - (abs(sum(month2['diff']))/sum(month2['pred'])))*100\n",
    "sum_true2 = sum(month2['true'])\n",
    "sum_pred2 = sum(month2['pred'])\n",
    "sum_diff2 = sum(month2['diff'])\n",
    "fnl_rslt_W.append([Algo,'April',Art_Code,Zone, Mill, sum_true2,sum_pred2,sum_diff2, acc2])\n",
    "\n",
    "acc3 = abs(1 - (abs(sum(month3['diff']))/sum(month3['pred'])))*100\n",
    "sum_true3 = sum(month3['true'])\n",
    "sum_pred3 = sum(month3['pred'])\n",
    "sum_diff3 = sum(month3['diff'])\n",
    "fnl_rslt_W.append([Algo,'May',Art_Code,Zone, Mill, sum_true3,sum_pred3,sum_diff3, acc3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rslt = pd.DataFrame(fnl_rslt_W, columns = ['Algo','Month','Art_Code','Zone','Mill','Sum_True','Sum_Pred','Sum_Diff','Acc'])\n",
    "rslt.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
